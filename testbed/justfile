set dotenv-load

RUN := env_var_or_default("RUN", "python")
DOCKER := env_var_or_default("DOCKER", "podman")
export SSHPASS:="giraff"
export MANAGER_PATH := "../manager"
export IOT_EMULATION_PATH := "../iot_emulation"
export FUNCTIONS_PATH := "../openfaas-functions"

# Entrypoint, run deploy and then tunnels
_default:
    @just --list

init user *FLAGS:
    #!/usr/bin/env bash
    cat <<EOF > ~/.ssh/config
    Host !access.grid5000.fr *.grid5000.fr
    User {{user}}
    ProxyJump {{user}}@access.grid5000.fr
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
    ForwardAgent yes
    EOF

    {{RUN}} integration.py init --g5k_user={{user}} {{FLAGS}}


lab: (_lab ".#jupyterlab")

labExport: (_lab ".#jupyterlabExport")

_lab drv max_memory_gb="20":
    #!/usr/bin/env bash
    if [ $(which systemd-run) ]; then
        systemd-run --scope -p MemoryMax={{max_memory_gb}}G --user nix run {{drv}}
    else
        nix run {{drv}}
    fi


# Open SSH tunnels
[private]
tunnels +FLAGS='':
    {{RUN}} integration.py tunnels {{FLAGS}}

# List end nodes of the Fog network
[private]
endpoints:
	{{RUN}} integration.py endpoints

_is_connected city_name_node_target $market_ip market_port:
    #!/usr/bin/env bash
    set -o pipefail
    raw_output=`curl -s "$market_ip:{{market_port}}/api/fog"`
    output=`echo "$raw_output" | jq '.[] | select(.tags[] == "{{city_name_node_target}}") | .id' | sed -nE 's/"(.*)"/\1/p'`
    status=$?
    if [ $status -ne 0 ]; then
        echo $raw_output
    fi
    if [ "$output" == "" ]; then
      echo $raw_output
      exit 1
    fi
    exit $status

_until_is_connected city_name_node_target market_ip market_port:
    #!/usr/bin/env bash
    status=1
    while [ $status -ne 0 ]; do
      just _is_connected {{city_name_node_target}} {{market_ip}} {{market_port}}
      status=$?
      if [ $status -ne 0 ]; then
        sleep 3
      fi
    done

_until_is_connected_timeout city_name_node_target market_ip market_port timeout:
    #!/usr/bin/env bash
    output=`timeout {{timeout}} bash -c "just _until_is_connected {{city_name_node_target}} {{market_ip}} {{market_port}}" 2>&1`
    status=$?
    if [ $status -ne 0 ]; then
      echo "Failed to check connection to {{city_name_node_target}} w/ output: $output"
    fi
    exit $status


[private]
deploy fog_node_image market_image $DEPLOYMENT_NAME:
    #!/usr/bin/env bash
    echo "REFRESH?: $REFRESH"
    if [ "$REFRESH" = "true" ] ; then
        {{RUN}} integration.py restart
    else
        {{RUN}} integration.py up --name="$DEPLOYMENT_NAME" --walltime "$DEPLOYMENT_WALLTIME" --force
    fi
    just _deploy {{fog_node_image}} {{market_image}}

[private]
refresh fog_node_image market_image $DEPLOYMENT_NAME:
    {{RUN}} integration.py restart
    just _deploy {{fog_node_image}} {{market_image}}

# Delete the Job on grid'5000 and local EnosLib files
[private]
clean:
    {{RUN}} integration.py clean || true
    rm -rf enos_* current cachedir __enos*

# Refresh the container images hosted by k3s on all deployed nodes
_deploy fog_node_image market_image:
    #!/usr/bin/env bash
    set -e
    {{RUN}} integration.py network
    {{RUN}} integration.py iot-emulation
    {{RUN}} integration.py k3s-setup
    {{RUN}} integration.py k3s-deploy --fog_node_image={{fog_node_image}} --market_image={{market_image}}

[private]
expe $IOT_IP $MARKET_IP $TARGET_NODES:
    {{RUN}} expe.py

[private]
scenario archive_name +city_name_node_targets:
    #!/usr/bin/env bash
    _status=0
    trap "_status=1 _localstatus=\$?" ERR
    _localstatus=0

    NODE_TARGETS=()

    MARKET_IP=$({{RUN}} integration.py market-ip | grep address | sed 's/address: //')
    # Create bg tasks, push their pid in an array and check after waiting for each when one has failed
    pids=()
    echo "Checking {{city_name_node_targets}}"
    for city in {{city_name_node_targets}}; do
        just _until_is_connected_timeout $city $MARKET_IP $MARKET_LOCAL_PORT 300&
        pids+=($!)
    done

    error_occured=0

    for pid in "${pids[@]}"; do
      wait "$pid"
      exit_status=$?
      if [ $exit_status -ne 0 ]; then
        error_occured=1
      fi
    done
    if [ $error_occured -ne 0 ]; then
      echo "At least one connection failed to be checked in time. Exiting..."
      exit 1
    fi

    for city in {{city_name_node_targets}}; do
        echo "Checking connection to $city"
        NODE_TARGETS+=($(curl "$MARKET_IP:$MARKET_LOCAL_PORT/api/fog" | jq ".[] | select(.tags[] == \"$city\") | .id" | sed -nE 's/"(.*)"/\1/p'))
    done

    if (( _localstatus > 0 )); then
        printf "Failed to get info on fog nodes (%s)" "$_localstatus"
        exit $_status
    fi
    _localstatus=0

    IOT_IP=$(just endpoints | sed -nE 's/Iot emulation IP -> (.*)/\1/p')
    printf -v joined '%s\t' "${NODE_TARGETS[@]}"
    export TARGET_NODE_NAMES="{{city_name_node_targets}}"
    if (( _localstatus > 0 )); then
        printf "Failed to get endpoints (%s)" "$_localstatus"
        exit $_status
    fi
    _localstatus=0

    just expe $IOT_IP $MARKET_IP "$joined"
    if (( _localstatus > 0 )); then
        printf "Experiments failed (%s)" "$_localstatus"
    fi

    if (( _localstatus == 0 )); then
        sleep $WAIT_TIME

        export COLLECT_ARCHIVE_NAME="{{archive_name}}"
        {{RUN}} integration.py collect

        if (( _localstatus > 0 )); then
            printf "Failed to collect metrics (%s)" "$_localstatus"
            exit $_status
        fi
    fi

    sleep 60

    if [ "$DEV" = "true" ]; then
        printf "DEV activated ; waiting indefinitely\n"
        sleep 9999999999;
    fi

    exit $_status

[private]
scenarii +city_name_node_targets:
    #!/usr/bin/env bash
    set -e

    function run_scenario() {
        echo "Using image $IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2 and $IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3"
        if [ $1 -eq 1 ]; then
            just deploy "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3" $DEPLOYMENT_NAME
        else
            just refresh "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME$3" $DEPLOYMENT_NAME \
            || just deploy "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$COMMON_IMAGE_NAME:$3" $DEPLOYMENT_NAME
        fi
        just tunnels --command="'just scenario \"$DEPLOYMENT_NAME-$2-$3\" {{city_name_node_targets}}'"
    }

    echo "Deploying..."

    echo 'will cite' | parallel --citation &> /dev/null || true

    export -f run_scenario
    parallel --tty --shuf \
        --joblog ./joblog \
        run_scenario {#} {} \
        ::: $(echo ${FOG_NODE_IMAGE_TAGS[@]}) \
        :::+ $(echo ${MARKET_IMAGE_TAGS[@]})

    for INDEX in $(seq 1 3); do
        parallel --tty --joblog ./joblog --retry-failed
    done

collect:
    mkdir -p metrics
    {{RUN}} integration.py collect --address $INFLUX_ADDRESS

_collect:
    mkdir -p metrics
    {{RUN}} integration.py collect

logs *FLAGS:
    {{RUN}} integration.py logs {{FLAGS}}

[private]
docker_enos name expe_dir cmd="bash":
    #!/usr/bin/env bash
    set -ex
    eval $(ssh-agent -s)
    rsync -rL {{justfile_directory()}}/* {{expe_dir}}

    echo "LOAD_NET: $LOAD_NETWORK_FILE"

    export REFRESH="false"
    if {{DOCKER}} ps -a --format '{{{{.Names}}}}' | grep -wq "{{name}}"; then
        export REFRESH="true"
        {{DOCKER}} exec "{{name}}" bash -c -E "export REFRESH=$REFRESH; {{cmd}}"
    else
        {{DOCKER}} run -it --rm \
            --privileged \
            --cap-add=ALL \
            --workdir /home/enos \
            -v /lib/modules:/lib/modules \
            -v {{expe_dir}}:/home/enos \
            -v {{justfile_directory()}}/metrics-arks:/home/enos/metrics-arks \
            -v {{justfile_directory()}}/logs:/home/enos/logs \
            -v $LOAD_NETWORK_FILE:/home/enos/net:ro \
            -v ~/.python-grid5000.yaml:/root/.python-grid5000.yaml:ro \
            -v ~/.ssh/id_rsa:/root/.ssh/id_rsa:ro \
            -v ~/.ssh/id_rsa.pub:/root/.ssh/id_rsa.pub:ro \
            -v $(readlink -f $SSH_AUTH_SOCK):/ssh-agent \
            -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro \
            -e SSH_AUTH_SOCK=/ssh-agent \
            -e DEPLOYMENT_NAME="{{name}}" \
            -e EXPE_LOAD_FILE=/home/enos/requests \
            -e NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY=$NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY \
            -e NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY=$NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY \
            -e NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY=$NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY \
            -e NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY=$NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY \
            -e LOAD_NETWORK_FILE=/home/enos/net \
            -e REFRESH="false" \
            --name "{{name}}" \
            --cgroup-manager=cgroupfs \
            enos_deployment:latest bash -c -E "{{cmd}}"
        fi


[private]
docker_scenarii name expe_dir +city_name_node_targets:
    echo "Generating requests for all subsequent experiments..."
    EXPE_SAVE_FILE={{expe_dir}}/requests TARGET_NODE_NAMES="{{city_name_node_targets}}" {{RUN}} expe.py
    just docker_enos {{name}} {{expe_dir}} "just scenarii {{city_name_node_targets}} ; just clean || ."

_docker_campaign name expe_dir:
    #!/usr/bin/env bash
    set -e
    cities=()
    for input in $({{RUN}} integration.py iot-connections); do cities[${#cities[@]}]="'$input'"; done
    just docker_scenarii {{name}} {{expe_dir}} ${cities[@]}

single_campaign name dotenvfile:
    #!/usr/bin/env bash
    set -ex
    expe_dir="/tmp/{{name}}"
    mkdir -p $expe_dir
    cp {{dotenvfile}} $expe_dir/.env
    cp definitions.py $expe_dir/definitions.py
    mkdir -p metrics-arks logs

    today=$( date +%Y%m%d )
    number=0
    fname={{name}}-$today.log
    while [ -e "$fname" ]; do
        printf -v fname '%s-%02d.log' "{{name}}-$today" "$(( ++number ))"
    done

    echo "qsdklhjfjqhsjok: $LOAD_NETWORK_FILE"

    mkdir -p logs_campaign
    just _docker_campaign {{name}} $expe_dir |& tee -a logs_campaign/$fname

[private]
build_required_images user:
    #!/usr/bin/env bash
    set -e

    read -ra tags <<<"$FOG_NODE_IMAGE_TAGS"
    read -ra market_tags <<<"$MARKET_IMAGE_TAGS"

    commands=(
        "cd $MANAGER_PATH && nix develop .#manager -c just ghcr {{user}} $(echo ${tags[@]}) $(echo ${market_tags[@]})"
        "cd $IOT_EMULATION_PATH && nix develop .#iot_emulation -c just ghcr {{user}}"
        "cd $FUNCTIONS_PATH && nix develop .#openfaas-functions -c just ghcr_all {{user}}"
    )

    parallel --will-cite --halt-on-error 2 {1} 2> /dev/null ::: "${commands[@]}"
    echo -e "[{{file_name(justfile_directory())}}] all images uploaded \033[1;32mOK\033[0m"

[private]
docker_campaign user variation="valuation_rates" experiments_dotfile=".experiments.env"  single_experiment_dotenvfile=".env": (build_required_images user)
    #!/usr/bin/env bash
    image_path=$(nix build --extra-experimentafl-features nix-command --extra-experimental-features flakes .#docker --print-out-paths --no-link --quiet)
    {{DOCKER}} load < $image_path
    nix develop --extra-experimental-features "nix-command flakes" -c just _docker_campaign_in_env {{variation}} {{experiments_dotfile}} {{single_experiment_dotenvfile}}

_docker_campaign_in_env variation experiments_dotfile single_experiment_dotenvfile:
    #!/usr/bin/env bash
    set -ex

    function expe_command() {
        set -e
        export ii=$1

        sleep 1

        # Calculate current time in seconds
        current_time=$( date +%s )

        # Convert job duration to seconds
        IFS=":" read hours minutes seconds <<< "${DEPLOYMENT_WALLTIME}"
        job_duration_seconds=$(bc <<< "${hours}*3600 + ${minutes}*60 + ${seconds}")

        # Calculate threshold in seconds
        next_day=$(date -d ${DO_NOT_EXECUTE_IF_ENDING_AFTER} +"%Y%m%d")
        threshold_time=$(date -d "${next_day} ${DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR}" +%s)

        # Compare times and decide whether to execute the command
        if (( current_time + job_duration_seconds > threshold_time )); then
            >&2 echo "Job will finish after $DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR the '$DO_NOT_EXECUTE_IF_ENDING_AFTER' day. Command will not be executed."
            exit 127
        fi

        timeout --foreground ${job_duration_seconds} just single_campaign "{{variation}}{{single_experiment_dotenvfile}}_$ii" {{single_experiment_dotenvfile}}
    }

    # Import all the settings for multiple experiments and load the var as env vars
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport

    if [ "$DEV" = "true" ]; then
        if [ "$DEV_NETWORK" = "true" ]; then
            export LOAD_NETWORK_FILE=$(mktemp)
        else
            export SAVE_NETWORK_FILE=$(mktemp)
            set -- $SIZE_MULTIPLIERS
            export SIZE_MULTIPLIER=$1
            set -- $MIN_NUMBER_VMS
            export MIN_NB_VMS=$1
            set -- $MAX_NUMBER_NODES
            export MAX_NB_NODES=$1

            {{RUN}} definitions.py
            export LOAD_NETWORK_FILE=$SAVE_NETWORK_FILE

            unset SAVE_NETWORK_FILE
        fi
        just single_campaign "{{variation}}{{single_experiment_dotenvfile}}_DEV" {{single_experiment_dotenvfile}}
        exit 0
    fi

    mkdir -p $JOB_DIR
    if [ $TYPE == "first_run" ]; then
        rm -rf $JOB_DIR/*
        parallel --will-cite \
            SAVE_NETWORK_FILE=$JOB_DIR/{1}-{4}.net \
            SIZE_MULTIPLIER={1} \
            MIN_NB_VMS={2} \
            MAX_NB_NODES={3} \
            {{RUN}} definitions.py \
            ::: $SIZE_MULTIPLIERS \
            :::+ $MIN_NUMBER_VMS \
            :::+ $MAX_NUMBER_NODES \
            ::: $(seq 1 $NB_REPETITIONS)
    fi

    for i in $(seq 1 $NB_REPETITIONS); do
        args+=("")
    done

    export free_port=$(comm -23 <(seq 49152 65535 | sort) <(ss -Htan | awk '{print $4}' | cut -d':' -f2 | sort -u) | shuf | head -n 1)

    function encapsulated_expe_command() {
        set -ex
        export NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY=$1
        export NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY=$2
        export NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY=$3
        export NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY=$4
        export LOAD_NETWORK_FILE=$6
        echo "Running the expe command with LOAD_NETWORK_FILE=$LOAD_NETWORK_FILE"
        expe_command $5
    }

    # Enable job control
    set -m
    export -f expe_command
    export -f encapsulated_expe_command

    set +e
    if [ ! -f $JOB_LOG ] && [ "$TYPE" != "first_run" ]; then
        >&2 echo "the action is TYPE=$TYPE; cannot run without JOB_LOG=$JOB_LOG existing"
        exit 1
    fi
    if [ $TYPE == "retry" ]; then
        (parallel --will-cite --retry-failed --joblog $JOB_LOG)
    else
        cmd=$(cat <<EOF
        --joblog $JOB_LOG \
        -j $NB_IN_PARALLEL \
        encapsulated_expe_command {1} {2} {3} {4} {#} '$JOB_DIR/'{5}-{6}.net \
        ::: $NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY \
        :::+ $NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY \
        ::: $NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY \
        :::+ $NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY \
        ::: $SIZE_MULTIPLIERS \
        ::: $(seq 1 $NB_REPETITIONS)
    EOF
    )
        if [ $TYPE == "resume" ]; then
            parallel --will-cite --resume $cmd
        else
            rm $JOB_LOG || true
            parallel --will-cite $cmd
        fi
    fi

    echo "Here is the JOB_LOG:"
    cat $JOB_LOG

dev:
    nix develop --extra-experimental-features nix-command --extra-experimental-features flakes

dry-experiment $CLUSTER SIZE_MULTIPLIERS:
    #!/usr/bin/env bash
    parallel --will-cite -k \
        export SIZE_MULTIPLIER={1} FILE='$(mktemp)' \
        ";" SAVE_NETWORK_FILE='$FILE' {{RUN}} definitions.py ">" /dev/null \
        "&&" LOAD_NETWORK_FILE='$FILE' {{RUN}} integration.py up --dry-run \
        ";" rm '$FILE' \
        ::: {{SIZE_MULTIPLIERS}}

sim filename="sim" nb_iter="1" $methods="" $pricing="" $RANDOM_SEED_INIT="" NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY="5" NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY="5" NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY="100" NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY="100" SIZE_MULTIPLIERS="1":
    #!/usr/bin/env bash
    export cities=()
    export pricing=${pricing:=$({{RUN}} simulator.py 2>/dev/null | sed -n 's/PRICING_STRATEGY not in \[\(.*\)\].*/\1/p')}
    export methods=${methods:=$({{RUN}} simulator.py 2>/dev/null | sed -n 's/PLACEMENT_STRATEGY not in \[\(.*\)\].*/\1/p')}
    export CSV_OUT_DIR=$(mktemp -d)

    parallel --will-cite SAVE_NETWORK_FILE=$CSV_OUT_DIR/{1}-{2}.net SIZE_MULTIPLIER={1} {{RUN}} definitions.py > /dev/null ::: {{SIZE_MULTIPLIERS}} ::: $(seq 1 {{nb_iter}})

    time parallel --will-cite --keep-order  \
        --memsuspend 3G \
        JOB_INDEX={#} \
        NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY={1} \
        NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY={2} \
        NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY={3} \
        NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY={4} \
        RANDOM_SEED='$(shuf -i 0-2560000 -n 1)' \
        just _sim $CSV_OUT_DIR/{5}-{6}.net \
        ::: {{NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY}} \
        :::+ {{NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY}} \
        ::: {{NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY}} \
        :::+ {{NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY}} \
        ::: {{SIZE_MULTIPLIERS}} \
        ::: $(seq 1 {{nb_iter}})

    rm ./{{filename}}.data.csv || .
    touch ./{{filename}}.data.csv
    readarray -d '' entries < <(printf '%s\0' $CSV_OUT_DIR/*.data.csv | sort -zV)
    for file in "${entries[@]}"; do
        cat $file >> ./{{filename}}.data.csv
    done
    rm ./{{filename}}.levels.csv || .
    touch ./{{filename}}.levels.csv
    readarray -d '' entries < <(printf '%s\0' $CSV_OUT_DIR/*.levels.csv | sort -zV)
    for file in "${entries[@]}"; do
        cat $file >> ./{{filename}}.levels.csv
    done

    rm -r $CSV_OUT_DIR

_sim $LOAD_NETWORK_FILE:
    #!/usr/bin/env bash
    export EXPE_SAVE_FILE=$(mktemp)

    inputs=$({{RUN}} integration.py iot-connections)
    for input in $inputs; do cities[${#cities[@]}]="'$input'"; done
    export TARGET_NODE_NAMES="${cities[@]}"
    {{RUN}} expe.py >&2
    parallel --will-cite --memsuspend 3G \
        PLACEMENT_STRATEGY={1} \
        PRICING_STRATEGY={2} \
        JOB_INDEX=$JOB_INDEX{#} \
        JOB_ID=$JOB_INDEX-{#} \
        {{RUN}} simulator.py \
        ::: $methods \
        ::: $pricing

    rm $EXPE_SAVE_FILE >&2

simple_sim $PLACEMENT_STRATEGY $PRICING_STRATEGY:
    #!/usr/bin/env bash
    set -e
    export SIZE_MULTIPLIER=1
    export cities=()
    inputs=$(SAVE_NETWORK_FILE=./network {{RUN}} integration.py iot-connections)
    for input in $inputs; do cities[${#cities[@]}]="'$input'"; done
    export EXPE_SAVE_FILE=./requests
    export TARGET_NODE_NAMES="${cities[@]}"
    export RANDOM_SEED=42
    export LOAD_NETWORK_FILE=./network
    [[ -f $EXPE_SAVE_FILE ]] || {{RUN}} expe.py
    {{RUN}} simulator.py > sim.simple.dump.csv

upload experiments_dotfile=".experiments.env" skip_vms="false":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport
    city=$({{RUN}} master.py get-city)
    if [ {{skip_vms}} != "true" ]; then
      echo "Building VMs"
      vm_path=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#enosvm --print-out-paths --no-link --quiet 2> /dev/null)/nixos.qcow2
      (rsync -cazpq --inplace --stats --perms --chmod=u+rwx,g+rwx,o+rwx $vm_path $city.grid5000.fr:~/nixos.env.qcow2 2> /dev/null \
        && echo -e "[{{file_name(justfile_directory())}}] master VM uploaded \033[32mOK\033[0m")&

      (sh -c "cd iso && nix develop .#iso -c just upload $city 2> /dev/null" \
        && echo -e "[{{file_name(justfile_directory())}}] fog_node VM uploaded \033[32mOK\033[0m")&
    else
      echo "Not building VMs"
    fi

    ssh $city.grid5000.fr mkdir -p enosvm 2> /dev/null

    parallel --will-cite rsync -cazpq --inplace --stats --perms --chmod=u+rwx,g+rwx,o+rwx {} $city.grid5000.fr:~/enosvm/{} 2> /dev/null \
        ::: *.py .env {{experiments_dotfile}} justfile pipelines
    echo -e "[{{file_name(justfile_directory())}}] config files uploaded \033[32mOK\033[0m"

    wait
    echo -e "[{{file_name(justfile_directory())}}] all files rsynced \033[1;32mOK\033[0m"


master_exec user name experiments_dotfile=".experiments.env" skip_vms="false":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport

    city=$({{RUN}} master.py get-city)
    username=$({{RUN}} master.py get-username)
    echo "nfs:/export/home/$username" | tee iso/config/g5k.nfs.txt
    echo "ntp.$city.grid5000.fr" | tee iso/config/ntp-servers.txt

    declare -a statuses

    just upload {{experiments_dotfile}} {{skip_vms}}& pid1=$!
    just build_required_images {{user}}& pid2=$!

    wait $pid1
    statuses[0]=$?

    wait $pid2
    statuses[1]=$?

    for status in "${statuses[@]}"; do
      if [ $status -ne 0 ]; then
        echo "A command I waited for failed"
        exit $status
      fi
    done

    {{RUN}} master.py up --name {{name}} --walltime $MASTER_WALLTIME --force
    {{RUN}} master.py run-command

master_refresh user name experiments_dotfile=".experiments.env" skip_rebuild="false":
    #!/usr/bin/env bash
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport

    pids=()
    just upload {{experiments_dotfile}} "true"&
    pids+=($!)
    ([ "{{skip_rebuild}}" = "true" ] || just build_required_images {{user}})&
    pids+=($!)

    for pid in "${pids[@]}"; do
      wait $pid
      if [ $? -ne 0 ]; then
        echo "A command errored"
        exit 1
      fi
    done

    set -e
    {{RUN}} master.py run-command-refresh

master_docker_campaign variation="valuation_rates" experiments_dotfile=".experiments.env"  single_experiment_dotenvfile=".env":
    just _docker_campaign_in_env {{variation}} {{experiments_dotfile}} {{single_experiment_dotenvfile}}

master_run:
    nix develop .#enosvm -c just _master_run

_master_run:
    #!/usr/bin/env bash
    set -e
    vm_path=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#enosvm --print-out-paths --no-link --quiet)/nixos.qcow2
    temp=nixos.env.qcow2
    cp $vm_path $temp
    chmod u+rwx $temp

    qemu-kvm \
        -cpu max \
        -name nixos \
        -m 4096 \
        -smp 4 \
        -drive cache=writeback,file="$temp",id=drive1,if=none,index=1,werror=report -device virtio-blk-pci,drive=drive1 \
        -net nic,netdev=user.0,model=virtio -netdev user,id=user.0,hostfwd=tcp::2222-:22 \
        -enable-kvm \
        -nographic&

    wait

master_ssh_in:
    nix develop .#enosvm -c sshpass -e ssh -t -oUserKnownHostsFile=/dev/null -oStrictHostKeyChecking=no root@127.0.0.1 -p 2222

get_metrics_back folder="metrics-arks" experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport
    city=$({{RUN}} master.py get-city)
    echo $city
    mkdir -p metrics-arks
    ssh $city.grid5000.fr ls {{folder}} | parallel --will-cite -j 4 -v rsync -cazp --progress $city.grid5000.fr:~/{{folder}}/{} ./metrics-arks/{}

[private]
test_expe  experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport
    export TARGET_NODE_NAMES=toto
    export TARGET_NODES=toto
    EXPE_SAVE_FILE=toto.txt python expe.py
