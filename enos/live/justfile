set dotenv-load

RUN := env_var_or_default("RUN", "python")
DOCKER := env_var_or_default("DOCKER", "podman")
export MANAGER_PATH := "../../manager"
export IOT_EMULATION_PATH := "../../iot_emulation"
export FUNCTIONS_PATH := "../../openfaas-functions"

# Entrypoint, run deploy and then tunnels
_default:
    @just --list

init user *FLAGS:
    #!/usr/bin/env bash
    cat <<EOF > ~/.ssh/config
    Host !access.grid5000.fr *.grid5000.fr
    User {{user}}
    ProxyJump {{user}}@access.grid5000.fr
    StrictHostKeyChecking no
    UserKnownHostsFile /dev/null
    ForwardAgent yes
    EOF

    {{RUN}} integration.py init --g5k_user={{user}} {{FLAGS}}

lab:
    nix run .#jupyterlab

labExport:
    nix run .#jupyterlabExport

# Open SSH tunnels
tunnels +FLAGS='':
    {{RUN}} integration.py tunnels {{FLAGS}}

# List end nodes of the Fog network
endpoints:
	{{RUN}} integration.py endpoints

_is_connected city_name_node_target market_port:
    #!/usr/bin/env bash
    market_ip=$({{RUN}} integration.py market-ip | grep address | sed 's/address: //')
    if [[ $(curl -s "$market_ip:{{market_port}}/api/fog" | jq '.[] | select(.tags[] == "{{city_name_node_target}}") | .id' | sed -nE 's/"(.*)"/\1/p') ]]; then
        echo "✅ {{city_name_node_target}}@$market_ip is connected"
    else
        echo "❌ {{city_name_node_target}}@$market_ip"
    fi

is_connected city_name_node_target market_local_port:
    watch --no-title --color --no-wrap just _is_connected {{city_name_node_target}} {{market_local_port}}

deploy fog_node_image market_image $DEPLOYMENT_NAME:
    {{RUN}} integration.py up --name="$DEPLOYMENT_NAME" --walltime "$DEPLOYMENT_WALLTIME" --force
    just _deploy {{fog_node_image}} {{market_image}}

refresh fog_node_image market_image $DEPLOYMENT_NAME:
    {{RUN}} integration.py restart
    just _deploy {{fog_node_image}} {{market_image}}

# Delete the Job on grid'5000 and local EnosLib files
clean:
    {{RUN}} integration.py clean || true
    rm -rf enos_* current cachedir __enos*   

# Refresh the container images hosted by k3s on all deployed nodes
_deploy fog_node_image market_image:
    #!/usr/bin/env bash
    set -e
    {{RUN}} integration.py network

    {{RUN}} integration.py iot-emulation&
    ({{RUN}} integration.py k3s-setup && \
        {{RUN}} integration.py k3s-deploy --fog_node_image={{fog_node_image}} --market_image={{market_image}})&
    
    wait

expe $IOT_IP $MARKET_IP $TARGET_NODES:
    {{RUN}} expe.py

scenario archive_name +city_name_node_targets:
    #!/usr/bin/env bash
    set -ex
    NODE_TARGETS=()
    
    sleep 60

    MARKET_IP=$({{RUN}} integration.py market-ip | grep address | sed 's/address: //')
    for city in {{city_name_node_targets}}; do
        echo "Checking connection to $city"
        timeout 360 bash -c "until [[ '$(just _is_connected $city $MARKET_LOCAL_PORT)' =~ '✅' ]]; do sleep 10 && echo -e '.'; done"
        NODE_TARGETS+=($(curl "$MARKET_IP:$MARKET_LOCAL_PORT/api/fog" | jq ".[] | select(.tags[] == \"$city\") | .id" | sed -nE 's/"(.*)"/\1/p'))
    done
    IOT_IP=$(just endpoints | sed -nE 's/Iot emulation IP -> (.*)/\1/p')
    printf -v joined '%s\t' "${NODE_TARGETS[@]}"
    export TARGET_NODE_NAMES="{{city_name_node_targets}}"

    sleep 60
    
    just expe $IOT_IP $MARKET_IP "$joined"
    
    sleep $WAIT_TIME

    export COLLECT_ARCHIVE_NAME="{{archive_name}}"
    {{RUN}} integration.py collect

    sleep 60

    if [ $DEV ]; then sleep 9999999999; fi

scenarii +city_name_node_targets:
    #!/usr/bin/env bash
    set -e

    function run_scenario() {
        echo "Using image $IMAGE_REGISTRY/$FOG_NODE_IMAGE_NAME:$2 and $IMAGE_REGISTRY/$MARKET_IMAGE"
        if [ $1 -eq 1 ]; then
            just deploy "$IMAGE_REGISTRY/$FOG_NODE_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$MARKET_IMAGE" $DEPLOYMENT_NAME
        else
            # just refresh "$IMAGE_REGISTRY/$FOG_NODE_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$MARKET_IMAGE" $DEPLOYMENT_NAME \
            # || just deploy "$IMAGE_REGISTRY/$FOG_NODE_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$MARKET_IMAGE" $DEPLOYMENT_NAME
            just deploy "$IMAGE_REGISTRY/$FOG_NODE_IMAGE_NAME:$2" "$IMAGE_REGISTRY/$MARKET_IMAGE" $DEPLOYMENT_NAME
        fi
        just tunnels --command="'just scenario \"$DEPLOYMENT_NAME-$2\" {{city_name_node_targets}}'"
    }

    echo "Deploying..."

    echo 'will cite' | parallel --citation &> /dev/null || true

    export -f run_scenario
    parallel --tty --shuf \
        --joblog ./joblog \
        run_scenario {#} {} \
        ::: $(echo ${FOG_NODE_IMAGE_TAGS[@]})

    for INDEX in $(seq 1 3); do
        parallel --tty --joblog ./joblog --retry-failed
    done

    just clean || .

collect:
    mkdir -p metrics
    {{RUN}} integration.py collect --address $INFLUX_ADDRESS

_collect:
    mkdir -p metrics
    {{RUN}} integration.py collect

logs *FLAGS:
    {{RUN}} integration.py logs {{FLAGS}}

vpn:
    #!/usr/bin/env bash
    set -e
    modprobe tun
    rm -rf grid5000-openvpn || true
    mkdir grid5000-openvpn
    unzip grid5000-openvpn.zip -d grid5000-openvpn
    cd grid5000-openvpn
    cat /root/.python-grid5000.yaml | grep 'password: ' | sed 's/password: //' > grid5000vpnpassword
    cat <<EOF >> Grid5000_VPN.ovpn
    script-security 2
    up /etc/openvpn/update-resolv-conf
    down /etc/openvpn/update-resolv-conf
    askpass "$PWD/grid5000vpnpassword"
    daemon
    EOF
    openvpn Grid5000_VPN.ovpn

sshconfig:
    #!/usr/bin/env bash
    set -e
    login=$(cat /root/.python-grid5000.yaml | grep 'username: ' | sed 's/username: //')

docker_enos name expe_dir cmd="bash":
    #!/usr/bin/env bash
    set -e
    {{DOCKER}} run -it --rm \
        --privileged \
        --cap-add=ALL \
        --workdir /home/enos \
        -v /lib/modules:/lib/modules \
        -v {{justfile_directory()}}/integration.py:/home/enos/integration.py:ro \
        -v {{justfile_directory()}}/collect.py:/home/enos/collect.py:ro \
        -v {{expe_dir}}/definitions.py:/home/enos/definitions.py:ro \
        -v {{justfile_directory()}}/expe.py:/home/enos/expe.py:ro \
        -v {{justfile_directory()}}/justfile:/home/enos/justfile:ro \
        -v {{justfile_directory()}}/metrics-arks:/home/enos/metrics-arks \
        -v {{justfile_directory()}}/logs:/home/enos/logs \
        -v {{expe_dir}}/.env:/home/enos/.env:ro \
        -v {{expe_dir}}/requests:/home/enos/requests:ro \
        -v $LOAD_NETWORK_FILE:/home/enos/net:ro \
        -v ~/.python-grid5000.yaml:/root/.python-grid5000.yaml:ro \
        -v ~/.ssh/id_rsa:/root/.ssh/id_rsa:ro \
        -v ~/.ssh/id_rsa.pub:/root/.ssh/id_rsa.pub:ro \
        -v $(readlink -f $SSH_AUTH_SOCK):/ssh-agent \
        -v /etc/ssl/certs/ca-certificates.crt:/etc/ssl/certs/ca-certificates.crt:ro \
        -e SSH_AUTH_SOCK=/ssh-agent \
        -e DEPLOYMENT_NAME="{{name}}" \
        -e EXPE_LOAD_FILE=/home/enos/requests \
        -e NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY=$NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY \
        -e NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY=$NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY \
        -e NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY=$NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY \
        -e NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY=$NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY \
        -e LOAD_NETWORK_FILE=/home/enos/net \
        --name "{{name}}" \
        --cgroup-manager=cgroupfs \
        enos_deployment:latest bash -c -E "just sshconfig && {{cmd}}"

# -v $GRID5000OPENVPNZIP:/home/enos/grid5000-openvpn.zip:ro \
# --cgroup-manager=cgroupfs fix needs to be investigated because ... Linux ?!?

docker_scenarii name tempdir +city_name_node_targets:
    echo "Generating requests for all subsequent experiments..."
    EXPE_SAVE_FILE={{tempdir}}/requests TARGET_NODE_NAMES="{{city_name_node_targets}}" {{RUN}} expe.py
    just docker_enos {{name}} {{tempdir}} "just scenarii {{city_name_node_targets}} ; just clean || ."
# just docker_enos {{name}} {{tempdir}} "just vpn && echo vnp is ok && just scenarii {{city_name_node_targets}} ; just clean || ."

_docker_campaign name tempdir:
    #!/usr/bin/env bash
    set -e
    cities=()
    for input in $({{RUN}} integration.py iot-connections); do cities[${#cities[@]}]="'$input'"; done
    just docker_scenarii {{name}} {{tempdir}} ${cities[@]}

single_campaign name dotenvfile:
    #!/usr/bin/env bash
    set -e
    tempdir=$(mktemp -d)
    cp {{dotenvfile}} $tempdir/.env
    cp definitions.py $tempdir/definitions.py
    mkdir -p metrics-arks logs

    today=$( date +%Y%m%d )
    number=0
    fname={{name}}-$today.log
    while [ -e "$fname" ]; do
        printf -v fname '%s-%02d.log' "{{name}}-$today" "$(( ++number ))"
    done

    mkdir -p logs_campaign
    just _docker_campaign {{name}} $tempdir |& tee -a logs_campaign/$fname


build_required_images user:
    #!/usr/bin/env bash
    set -e

    read -ra tags <<<"$FOG_NODE_IMAGE_TAGS"

    for (( i=0; i<${#tags[@]}; i++ )); do
        tags[$i]="fog_node_${tags[$i]}"
    done

    commands=(
        "cd $MANAGER_PATH && nix develop -c just ghcr {{user}} $(echo ${tags[@]})"
        "cd $IOT_EMULATION_PATH && nix develop -c just ghcr {{user}}"
        "cd $FUNCTIONS_PATH && nix develop -c just faas"
    )

    parallel --will-cite --lb ::: "${commands[@]}"

docker_campaign user variation="valuation_rates" experiments_dotfile=".experiments.env"  single_experiment_dotenvfile=".env": (build_required_images user)
    #!/usr/bin/env bash
    image_path=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#docker --print-out-paths --no-link --quiet)
    {{DOCKER}} load < $image_path
    nix develop --extra-experimental-features "nix-command flakes" -c just _docker_campaign_in_env {{variation}} {{experiments_dotfile}} {{single_experiment_dotenvfile}}

_docker_campaign_in_env variation experiments_dotfile single_experiment_dotenvfile:
    #!/usr/bin/env bash
    set -e
    
    function expe_command() {
        set -e
        export ii=$1

        sleep 1

        # Calculate current time in seconds
        current_time=$( date +%s )

        # Convert job duration to seconds
        IFS=":" read hours minutes seconds <<< "${DEPLOYMENT_WALLTIME}"
        job_duration_seconds=$(bc <<< "${hours}*3600 + ${minutes}*60 + ${seconds}")

        # Calculate threshold in seconds
        next_day=$(date -d ${DO_NOT_EXECUTE_IF_ENDING_AFTER} +"%Y%m%d")
        threshold_time=$(date -d "${next_day} ${DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR}" +%s)

        # Compare times and decide whether to execute the command
        if (( current_time + job_duration_seconds > threshold_time )); then
            echo "Job will finish after $DO_NOT_EXECUTE_IF_ENDING_AFTER_HOUR the '$DO_NOT_EXECUTE_IF_ENDING_AFTER' day. Command will not be executed."
            exit 127
        fi

        timeout --foreground ${job_duration_seconds} just single_campaign "{{variation}}{{single_experiment_dotenvfile}}_$ii" {{single_experiment_dotenvfile}}
    }

    if [ $DEV ]; then 
        export LOAD_NETWORK_FILE=$(mktemp)
        just single_campaign "{{variation}}{{single_experiment_dotenvfile}}_DEV" {{single_experiment_dotenvfile}}
        exit 0
    fi


    # Import all the settings for multiple experiments and load the var as env vars
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport

    mkdir -p $JOB_DIR
    if [ $TYPE == "first_run" ]; then
        rm -rf $JOB_DIR/*
        timeout --preserve-status --foreground 5m \
            parallel --will-cite \
            SAVE_NETWORK_FILE=$JOB_DIR/{1}-{4}.net \
            SIZE_MULTIPLIER={1} \
            MIN_NB_VMS={2} \
            MAX_NB_NODES={3} \
            bash -c '"until timeout 15s {{RUN}} definitions.py; do : ; done"' \
            ::: $SIZE_MULTIPLIERS \
            :::+ $MIN_NUMBER_VMS \
            :::+ $MAX_NUMBER_NODES \
            ::: $(seq 1 $NB_REPETITIONS)
    fi

    for i in $(seq 1 $NB_REPETITIONS); do
        args+=("")
    done

    export free_port=$(comm -23 <(seq 49152 65535 | sort) <(ss -Htan | awk '{print $4}' | cut -d':' -f2 | sort -u) | shuf | head -n 1)

    function encapsulated_expe_command_mprocs() {
        set -e
        JOB_TERMINATION=$(mktemp)
        ctl=$(cat <<EOF
    export NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY=$1
    ; export NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY=$2
    ; export NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY=$3
    ; export NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY=$4
    ; export LOAD_NETWORK_FILE=$6
    ; bash -c "set -e; expe_command $5"
    ; exit_status=\$?
    ; exit \$(echo \$exit_status | tee $JOB_TERMINATION)
    EOF
        )
        mprocs --server 0:$free_port --ctl "{c: add-proc, cmd: '$ctl'}" || exit 1
        until [ $(wc -l < "${JOB_TERMINATION}") -ne 0 ]; do sleep 5; done
        job_status=$(cat $JOB_TERMINATION)
        rm $JOB_TERMINATION
        exit $job_status
    }

    # Enable job control
    set -m
    export -f expe_command
    export -f encapsulated_expe_command_mprocs
    mprocs --server 0:$free_port&
    
    set +e
    if [ ! -f $JOB_LOG ] && [ $TYPE != "first_run" ]; then
        echo "the action is TYPE=$TYPE; cannot run without JOB_LOG=$JOB_LOG existing"
        exit 1
    fi
    if [ $TYPE == "retry" ]; then
        (parallel --will-cite --retry-failed --joblog $JOB_LOG)&
    else
        cmd=$(cat <<EOF
        --joblog $JOB_LOG \
        -j $NB_IN_PARALLEL \
        encapsulated_expe_command_mprocs {1} {2} {3} {4} {#} '$JOB_DIR/'{5}-{6}.net \
        ::: $NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY \
        :::+ $NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY \
        ::: $NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY \
        :::+ $NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY \
        ::: $SIZE_MULTIPLIERS \
        ::: $(seq 1 $NB_REPETITIONS)
    EOF
    )
        if [ $TYPE == "resume" ]; then
            parallel --will-cite --resume $cmd&
        else
            rm $JOB_LOG || .
            parallel --will-cite $cmd&
        fi
    fi

    fg %1
    fg %2
    
    echo "Here is the JOB_LOG:"
    cat $JOB_LOG
   
dev:
    nix develop --extra-experimental-features nix-command --extra-experimental-features flakes

dry-experiment $CLUSTER SIZE_MULTIPLIERS:
    #!/usr/bin/env bash
    parallel --will-cite -k \
        export SIZE_MULTIPLIER={1} FILE='$(mktemp)' \
        ";" SAVE_NETWORK_FILE='$FILE' {{RUN}} definitions.py ">" /dev/null \
        "&&" LOAD_NETWORK_FILE='$FILE' {{RUN}} integration.py up --dry-run \
        ";" rm '$FILE' \
        ::: {{SIZE_MULTIPLIERS}}

sim filename="sim" nb_iter="1" $methods="" $pricing="" $RANDOM_SEED_INIT="" NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY="5" NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY="5" NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY="100" NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY="100" SIZE_MULTIPLIERS="1":
    #!/usr/bin/env bash
    export cities=()
    export pricing=${pricing:=$({{RUN}} simulator.py 2>/dev/null | sed -n 's/PRICING_STRATEGY not in \[\(.*\)\].*/\1/p')}
    export methods=${methods:=$({{RUN}} simulator.py 2>/dev/null | sed -n 's/PLACEMENT_STRATEGY not in \[\(.*\)\].*/\1/p')}
    export CSV_OUT_DIR=$(mktemp -d)

    parallel --will-cite SAVE_NETWORK_FILE=$CSV_OUT_DIR/{1}-{2}.net SIZE_MULTIPLIER={1} {{RUN}} definitions.py > /dev/null ::: {{SIZE_MULTIPLIERS}} ::: $(seq 1 {{nb_iter}})

    time parallel --will-cite --keep-order  \
        --memsuspend 3G \
        JOB_INDEX={#} \
        NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY={1} \
        NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY={2} \
        NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY={3} \
        NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY={4} \
        RANDOM_SEED='$(shuf -i 0-2560000 -n 1)' \
        just _sim $CSV_OUT_DIR/{5}-{6}.net \
        ::: {{NB_FUNCTIONS_LOW_REQ_INTERVAL_LOW_LATENCY}} \
        :::+ {{NB_FUNCTIONS_HIGH_REQ_INTERVAL_LOW_LATENCY}} \
        ::: {{NB_FUNCTIONS_LOW_REQ_INTERVAL_REST_LATENCY}} \
        :::+ {{NB_FUNCTIONS_HIGH_REQ_INTERVAL_REST_LATENCY}} \
        ::: {{SIZE_MULTIPLIERS}} \
        ::: $(seq 1 {{nb_iter}})

    rm ./{{filename}}.data.csv || .
    touch ./{{filename}}.data.csv
    readarray -d '' entries < <(printf '%s\0' $CSV_OUT_DIR/*.data.csv | sort -zV)
    for file in "${entries[@]}"; do
        cat $file >> ./{{filename}}.data.csv
    done
    rm ./{{filename}}.levels.csv || .
    touch ./{{filename}}.levels.csv
    readarray -d '' entries < <(printf '%s\0' $CSV_OUT_DIR/*.levels.csv | sort -zV)
    for file in "${entries[@]}"; do
        cat $file >> ./{{filename}}.levels.csv
    done

    rm -r $CSV_OUT_DIR

_sim $LOAD_NETWORK_FILE:
    #!/usr/bin/env bash
    export EXPE_SAVE_FILE=$(mktemp)

    inputs=$({{RUN}} integration.py iot-connections)
    for input in $inputs; do cities[${#cities[@]}]="'$input'"; done
    export TARGET_NODE_NAMES="${cities[@]}"
    {{RUN}} expe.py >&2
    parallel --will-cite --memsuspend 3G \
        PLACEMENT_STRATEGY={1} \
        PRICING_STRATEGY={2} \
        JOB_INDEX=$JOB_INDEX{#} \
        JOB_ID=$JOB_INDEX-{#} \
        {{RUN}} simulator.py \
        ::: $methods \
        ::: $pricing 
    
    rm $EXPE_SAVE_FILE >&2

simple_sim $PLACEMENT_STRATEGY $PRICING_STRATEGY:
    #!/usr/bin/env bash
    set -e
    export SIZE_MULTIPLIER=1
    export cities=()
    inputs=$(SAVE_NETWORK_FILE=./network {{RUN}} integration.py iot-connections)
    for input in $inputs; do cities[${#cities[@]}]="'$input'"; done
    export EXPE_SAVE_FILE=./requests 
    export TARGET_NODE_NAMES="${cities[@]}"
    export RANDOM_SEED=42
    export LOAD_NETWORK_FILE=./network
    [[ -f $EXPE_SAVE_FILE ]] || {{RUN}} expe.py
    {{RUN}} simulator.py > sim.simple.dump.csv

upload experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport
    city=$({{RUN}} master.py get-city)
    vm_path=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#enosvm --print-out-paths --no-link --quiet)/nixos.qcow2
    rsync -chavzP --inplace --stats --perms --chmod=u+rwx,g+rwx,o+rwx $vm_path $city.grid5000.fr:~/nixos.env.qcow2

master_exec user name experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -e
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport

    city=$({{RUN}} master.py get-city)
    username=$({{RUN}} master.py get-username)

    echo "nfs:/export/home/$username" | tee iso/config/g5k.nfs.txt
    echo "ntp.$city.grid5000.fr" | tee iso/config/ntp-servers.txt

    # just master_upload $city
    # bash -c "cd iso; nix develop -c just upload $city"
    # parallel --will-cite --lb ::: "just master_upload $city" "cd iso; nix develop -c just upload $city" "just build_required_images {{user}}"
    # just build_required_images {{user}}

    set +e

    {{RUN}} master.py up --name {{name}} --walltime $MASTER_WALLTIME --force
    {{RUN}} master.py run-command

master_docker_campaign variation="valuation_rates" experiments_dotfile=".experiments.env"  single_experiment_dotenvfile=".env":
    just _docker_campaign_in_env {{variation}} {{experiments_dotfile}} {{single_experiment_dotenvfile}}

master_run:    
    nix develop .#enosvm -c just _master_run

_master_run:    
    #!/usr/bin/env bash
    set -e
    vm_path=$(nix build --extra-experimental-features nix-command --extra-experimental-features flakes .#enosvm --print-out-paths --no-link --quiet)/nixos.qcow2
    temp=nixos.env.qcow2
    cp $vm_path $temp
    chmod u+rwx $temp

    qemu-kvm \
        -cpu max \
        -name nixos \
        -m 4096 \
        -smp 4 \
        -drive cache=writeback,file="$temp",id=drive1,if=none,index=1,werror=report -device virtio-blk-pci,drive=drive1 \
        -net nic,netdev=user.0,model=virtio -netdev user,id=user.0,hostfwd=tcp::2221-:22 \
        -enable-kvm \
        -nographic&
    
    wait

get_metrics_back folder="metrics-arks" experiments_dotfile=".experiments.env":
    #!/usr/bin/env bash
    set -o allexport
    source {{experiments_dotfile}}
    set +o allexport
    city=$({{RUN}} master.py get-city)
    echo $city
    mkdir -p metrics-arks
    ssh $city.grid5000.fr ls {{folder}} | parallel -j 4 -v rsync -chavzP --progress $city.grid5000.fr:~/{{folder}}/{} ./metrics-arks/{}
